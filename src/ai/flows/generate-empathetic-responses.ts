
// This is an AI-generated file. Do not edit directly.
'use server';
/**
 * @fileOverview Generates empathetic responses and relevant advice tailored to the user's situation.
 *
 * - generateEmpatheticResponse - A function that generates empathetic responses.
 * - EmpatheticResponseInput - The input type for the generateEmpatheticResponse function.
 * - EmpatheticResponseOutput - The return type for the generateEmpatheticResponse function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const ChatHistoryEntrySchema = z.object({
  role: z.enum(['user', 'ai']).describe('The role of the message sender.'),
  text: z.string().describe('The content of the message.'),
});

const EmpatheticResponseInputSchema = z.object({
  age: z.number().describe('The age of the user (13-50).'),
  genderIdentity: z.enum(['Male', 'Female', 'Non-Binary']).describe('The gender identity of the user.'),
  ethnicity: z.string().describe('The ethnicity of the user.'),
  vulnerableScore: z.number().min(0).max(10).describe('The vulnerability score of the user (0-10).'),
  anxietyLevel: z.enum(['Low', 'High']).describe('The anxiety level of the user.'), // Assuming Medium is mapped to High as per TherapyPage
  breakupType: z.enum(['Mutual', 'Ghosting', 'Cheating', 'Demise', 'Divorce']).describe('The type of breakup the user experienced.'),
  background: z.string().describe('The background of the user.'),
  // therapeuticNeeds removed, AI infers from context
  currentMessage: z.string().describe('The most recent message from the user.'),
  empathyLevel: z.number().min(0).max(5).describe('The current empathy level of the AI (0-5).'),
  chatHistory: z.array(ChatHistoryEntrySchema).optional().describe('The last few messages in the chat history for context.'),
});

export type EmpatheticResponseInput = z.infer<typeof EmpatheticResponseInputSchema>;

const EmpatheticResponseOutputSchema = z.object({
  response: z.string().describe('The empathetic response generated by the AI.'),
  updatedEmpathyLevel: z.number().min(0).max(5).describe('The updated empathy level of the AI, incremented by one if possible.'),
  detectedSentiment: z.string().optional().describe("The AI's brief analysis of the sentiment in the user's current message (e.g., 'sadness', 'frustration')."),
});

export type EmpatheticResponseOutput = z.infer<typeof EmpatheticResponseOutputSchema>;

export async function generateEmpatheticResponse(input: EmpatheticResponseInput): Promise<EmpatheticResponseOutput> {
  return generateEmpatheticResponseFlow(input);
}

const prompt = ai.definePrompt({
  name: 'empatheticResponsePrompt',
  input: {schema: EmpatheticResponseInputSchema},
  output: {schema: EmpatheticResponseOutputSchema},
  prompt: `You are an AI therapist specializing in providing empathetic responses and advice.
User Profile:
Age: {{{age}}}
Gender Identity: {{{genderIdentity}}}
Ethnicity: {{{ethnicity}}}
Vulnerable Score: {{{vulnerableScore}}}
Anxiety Level: {{{anxietyLevel}}}
Breakup Type: {{{breakupType}}}
Background: {{{background}}}

Current AI Empathy Level: {{{empathyLevel}}}

Conversation History (most recent messages):
{{#if chatHistory}}
{{#each chatHistory}}
{{role}}: {{text}}
{{/each}}
{{else}}
No previous messages in this snippet.
{{/if}}

User's Current Message:
"""
{{{currentMessage}}}
"""

Your Tasks:
1.  Analyze the user's current message and the conversation history. Identify the primary sentiment(s) expressed (e.g., "sadness," "frustration," "confusion," "relief"). Populate the 'detectedSentiment' field with your brief analysis (1-3 words).
2.  Generate an empathetic response. Acknowledge and reflect the user's expressed emotions. Use a rich vocabulary of feeling words. Be mindful of their vulnerability and anxiety level.
3.  Increment the empathy level for the 'updatedEmpathyLevel' field (current level + 1, max 5).

Always respond in British English, using medical terms where appropriate (e.g., "surgery," "patient"). Your response should sound natural and human, from the persona of a therapist. Do not ask "how are you?" or "do you need help?" as this is implied.

Ensure your output strictly follows the JSON schema.
  `,
});

const generateEmpatheticResponseFlow = ai.defineFlow(
  {
    name: 'generateEmpatheticResponseFlow',
    inputSchema: EmpatheticResponseInputSchema,
    outputSchema: EmpatheticResponseOutputSchema,
  },
  async input => {
    // Ensure empathyLevel does not exceed 5 before sending to prompt
    const currentEmpathy = Math.min(input.empathyLevel, 5);
    
    const {output} = await prompt({
      ...input,
      empathyLevel: currentEmpathy,
    });

    if (!output) {
      throw new Error('AI failed to generate an empathetic response.');
    }

    // Ensure the LLM correctly calculated updatedEmpathyLevel, or override if necessary.
    // The prompt asks the LLM to do this, so we primarily trust its output.
    // However, as a fallback, we can enforce the increment rule here if the LLM fails.
    let finalUpdatedEmpathyLevel = output.updatedEmpathyLevel;
    if (typeof finalUpdatedEmpathyLevel !== 'number' || finalUpdatedEmpathyLevel < currentEmpathy || finalUpdatedEmpathyLevel > currentEmpathy + 1) {
        finalUpdatedEmpathyLevel = Math.min(currentEmpathy + 1, 5);
    }
    finalUpdatedEmpathyLevel = Math.min(finalUpdatedEmpathyLevel, 5); // Cap at 5

    return {
      response: output.response,
      updatedEmpathyLevel: finalUpdatedEmpathyLevel,
      detectedSentiment: output.detectedSentiment,
    };
  }
);
